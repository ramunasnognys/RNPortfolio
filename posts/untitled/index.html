<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> | Ramunas Nognys</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Share+Tech+Mono&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" href="/css/theme.min.css">
    
    <link rel="stylesheet" href="/css/custom.min.e3c7ef98fdaf928ed19b2abf587f31fb9a65e9ea1616cf64e058e05a66c743a5.css" integrity="sha256-48fvmP2vko7Rmyq/WH8x&#43;5pl6eoWFs9k4FjgWmbHQ6U=">
</head>
<body>
    <header class="header">
    <div class="header-content">
        <a href="/" class="logo">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <rect x="2" y="2" width="20" height="20" stroke="#7C3AED" stroke-width="2" fill="#7C3AED" fill-opacity="0.1"/>
            </svg>
            Ramunas Nognys
        </a>
        <nav class="nav-links">
            <a href="/projects" class="nav-link">Projects</a>
            <a href="/blog" class="nav-link">Blog</a>
            <button class="theme-switch" id="theme-toggle" aria-label="Toggle theme">
                <svg class="theme-icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </nav>
    </div>
</header>

    <main>
        
<div class="content-wrapper">
    <div class="post-container">
        <article class="post-single">
        <header class="post-header">
            <div class="post-meta">
                
                <span class="reading-time">• 600 words • 3 min read</span>
            </div>
            <h1 class="post-title"></h1>
            
            
        </header>

        <div class="post-content">
            
            
            <h2 id="installation"><strong>Installation</strong></h2>
<ol>
<li>Open Git Bash on your Windows 11 system.</li>
<li>Create and activate a new conda environment (replace <code>janus-env</code> with your preferred name):
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">conda create -n janus-env <span class="nv">python</span><span class="o">=</span>3.8
</span></span><span class="line"><span class="cl">conda activate janus-env
</span></span></code></pre></div></li>
<li>Install the required dependencies:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">conda install pytorch torchvision torchaudio pytorch-cuda<span class="o">=</span>12.1 -c pytorch -c nvidia
</span></span><span class="line"><span class="cl">conda install -c conda-forge git
</span></span><span class="line"><span class="cl">pip install transformers
</span></span><span class="line"><span class="cl">pip install -e .
</span></span></code></pre></div></li>
<li>Clone the Janus repository:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">git clone https://github.com/deepseek-ai/Janus.git
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> Janus
</span></span><span class="line"><span class="cl">pip install -e .
</span></span></code></pre></div></li>
</ol>
<hr>
<h2 id="environment-setup"><strong>Environment Setup</strong></h2>
<ol>
<li>Ensure you have an NVIDIA GPU with CUDA installed. If not, download the CUDA toolkit from <a href="https://developer.nvidia.com/cuda-downloads">NVIDIA’s website</a>.</li>
<li>Verify CUDA installation by running:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">nvidia-smi
</span></span></code></pre></div></li>
<li>If using Windsurf IDE, ensure your project is set up with the correct Python interpreter (Python 3.8 or higher).</li>
</ol>
<hr>
<h2 id="multimodal-understanding-image-description"><strong>Multimodal Understanding (Image Description)</strong></h2>
<ol>
<li>
<p>Open a Python file in your preferred IDE (e.g., Windsurf IDE).</p>
</li>
<li>
<p>Import the necessary libraries and load the model:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">janus.models</span> <span class="kn">import</span> <span class="n">MultiModalityCausalLM</span><span class="p">,</span> <span class="n">VLChatProcessor</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">janus.utils.io</span> <span class="kn">import</span> <span class="n">load_pil_images</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model_path</span> <span class="o">=</span> <span class="s2">&#34;deepseek-ai/Janus-Pro-7B&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">vl_chat_processor</span> <span class="o">=</span> <span class="n">VLChatProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">tokenizer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vl_gpt</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vl_gpt</span> <span class="o">=</span> <span class="n">vl_gpt</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span></code></pre></div></li>
<li>
<p>Prepare your conversation and image:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;|User|&gt;&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&#34;&lt;image_placeholder&gt;</span><span class="se">\n</span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;images&#34;</span><span class="p">:</span> <span class="p">[</span><span class="n">image</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;|Assistant|&gt;&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span></code></pre></div></li>
<li>
<p>Load and process the image:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">pil_images</span> <span class="o">=</span> <span class="n">load_pil_images</span><span class="p">(</span><span class="n">conversation</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">prepare_inputs</span> <span class="o">=</span> <span class="n">vl_chat_processor</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">conversations</span><span class="o">=</span><span class="n">conversation</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">pil_images</span><span class="p">,</span> <span class="n">force_batchify</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">vl_gpt</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span></code></pre></div></li>
<li>
<p>Run the model to generate a response:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">vl_gpt</span><span class="o">.</span><span class="n">prepare_inputs_embeds</span><span class="p">(</span><span class="o">**</span><span class="n">prepare_inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">outputs</span> <span class="o">=</span> <span class="n">vl_gpt</span><span class="o">.</span><span class="n">language_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">attention_mask</span><span class="o">=</span><span class="n">prepare_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">eos_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">answer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">prepare_inputs</span><span class="p">[</span><span class="s1">&#39;sft_format&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">answer</span><span class="p">)</span>
</span></span></code></pre></div></li>
</ol>
<hr>
<h2 id="text-to-image-generation"><strong>Text-to-Image Generation</strong></h2>
<ol>
<li>
<p>Import the necessary libraries and load the model (same as above).</p>
</li>
<li>
<p>Define your text prompt:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;|User|&gt;&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;A stunning princess from kabul in red, white traditional clothing, blue eyes, brown hair&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;&lt;|Assistant|&gt;&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span><span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span></code></pre></div></li>
<li>
<p>Prepare the prompt and generate the image:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sft_format</span> <span class="o">=</span> <span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">apply_sft_template_for_multi_turn_prompts</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">conversations</span><span class="o">=</span><span class="n">conversation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">sft_format</span><span class="o">=</span><span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">sft_format</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&#34;&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">prompt</span> <span class="o">=</span> <span class="n">sft_format</span> <span class="o">+</span> <span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">image_start_tag</span>
</span></span></code></pre></div></li>
<li>
<p>Run the generation function:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@torch.inference_mode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">mmgpt</span><span class="p">:</span> <span class="n">MultiModalityCausalLM</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">vl_chat_processor</span><span class="p">:</span> <span class="n">VLChatProcessor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">cfg_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">image_token_num_per_image</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">576</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">img_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">384</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">parallel_size</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parallel_size</span><span class="o">*</span><span class="mi">2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">input_ids</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">vl_chat_processor</span><span class="o">.</span><span class="n">pad_id</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">mmgpt</span><span class="o">.</span><span class="n">language_model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">parallel_size</span><span class="p">,</span> <span class="n">image_token_num_per_image</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image_token_num_per_image</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">mmgpt</span><span class="o">.</span><span class="n">language_model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">past_key_values</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">mmgpt</span><span class="o">.</span><span class="n">gen_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
</span></span><span class="line"><span class="cl">        <span class="n">logit_cond</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">        <span class="n">logit_uncond</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="n">logit_uncond</span> <span class="o">+</span> <span class="n">cfg_weight</span> <span class="o">*</span> <span class="p">(</span><span class="n">logit_cond</span><span class="o">-</span><span class="n">logit_uncond</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">generated_tokens</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_token</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">img_embeds</span> <span class="o">=</span> <span class="n">mmgpt</span><span class="o">.</span><span class="n">prepare_gen_img_embeds</span><span class="p">(</span><span class="n">next_token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">img_embeds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dec</span> <span class="o">=</span> <span class="n">mmgpt</span><span class="o">.</span><span class="n">gen_vision_model</span><span class="o">.</span><span class="n">decode_code</span><span class="p">(</span><span class="n">generated_tokens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">parallel_size</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">img_size</span><span class="o">//</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">img_size</span><span class="o">//</span><span class="n">patch_size</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">dec</span> <span class="o">=</span> <span class="n">dec</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">((</span><span class="n">dec</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">visual_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">parallel_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">visual_img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">dec</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s1">&#39;generated_samples&#39;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parallel_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;generated_samples&#39;</span><span class="p">,</span> <span class="s2">&#34;img_</span><span class="si">{}</span><span class="s2">.jpg&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">visual_img</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">generate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">vl_gpt</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">vl_chat_processor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">prompt</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div></li>
</ol>
<hr>
<h2 id="troubleshooting"><strong>Troubleshooting</strong></h2>
<ul>
<li>Ensure CUDA is properly installed and recognized by running <code>nvidia-smi</code>.</li>
<li>Verify that the model is downloaded correctly by checking the <code>model_path</code>.</li>
<li>If you encounter missing dependencies, install them using <code>pip install -r requirements.txt</code>.</li>
</ul>
<p>Let me know if you need further clarification!</p>

            
            
        </div>

        <nav class="post-nav">
            
            
            
            <a class="nav-next" href="https://blog.ramunasnognys.tech/posts/personal-development-plan-pdp-for-devops-sre-role/">
                <div class="nav-indicator">
                    <span>Next</span>
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                </div>
                <span class="nav-title"></span>
            </a>
            
        </nav>
    </article>
    </div>

    
    <div class="table-of-contents">
        <div class="toc-title">Table of Contents</div>
        
        
        
        <nav id="TableOfContents">
  <ul>
    <li><a href="#installation"><strong>Installation</strong></a></li>
    <li><a href="#environment-setup"><strong>Environment Setup</strong></a></li>
    <li><a href="#multimodal-understanding-image-description"><strong>Multimodal Understanding (Image Description)</strong></a></li>
    <li><a href="#text-to-image-generation"><strong>Text-to-Image Generation</strong></a></li>
    <li><a href="#troubleshooting"><strong>Troubleshooting</strong></a></li>
  </ul>
</nav>
    </div>
    
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
            const id = entry.target.getAttribute('id');
            const tocLink = document.querySelector(`.table-of-contents nav a[href="#${id}"]`);
            
            if (tocLink) {
                if (entry.intersectionRatio > 0) {
                    document.querySelectorAll('.table-of-contents nav a').forEach(link => {
                        link.classList.remove('active');
                    });
                    tocLink.classList.add('active');
                }
            }
        });
    }, {
        rootMargin: '-20% 0px -80% 0px'
    });

    document.querySelectorAll('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').forEach((header) => {
        observer.observe(header);
    });
});
</script>

    </main>
    <footer class="footer">
    <div class="content-wrapper">
        <p>&copy; 2025 Ramunas Nognys. All rights reserved.</p>
    </div>
</footer>

    
    <script src="/js/theme.min.js"></script>
</body>
</html>
